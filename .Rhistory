<<<<<<< HEAD
rpart.plot(tree)
test <- read.delim('arbol_test.csv', sep=",", head = TRUE)
colnames(data)
pred <- predict(tree, test, type="class")
data <- read.delim('arbol_train.csv', sep=",", head = TRUE)
colnames(data)
tree <- rpart(Confirmed ~ ., data, method="class", minsplit = 2)
rpart.plot(tree)
test <- read.delim('arbol_test.csv', sep=",", head = TRUE)
colnames(data)
pred <- predict(tree, test, type="class")
data <- read.delim('arbol_train.csv', sep=",", head = TRUE)
colnames(data)
tree <- rpart(Confirmed ~ ., data, method="class", minsplit = 2)
rpart.plot(tree)
test <- read.delim('arbol_test.csv', sep=",", head = TRUE)
colnames(data)
pred <- predict(tree, test, type="class")
test <- read.delim('arbol_test.csv', sep=",", head = TRUE)
colnames(data)
pred <- predict(tree, test, type="class")
test <- read.delim('arbol_test.csv', sep=",", head = TRUE)
colnames(data)
pred <- predict(tree, test, type="class")
View(test)
data <- read.delim('arbol_train.csv', sep=",", head = TRUE)
colnames(data)
tree <- rpart(Confirmed ~ ., data, method="class", minsplit = 2)
rpart.plot(tree)
test <- read.delim('arbol_test.csv', sep=",", head = TRUE)
colnames(data)
pred <- predict(tree, test, type="class")
test <- read.delim('arbol_test.csv', sep=",", head = TRUE)
colnames(data)
pred <- predict(tree, test, type="class")
test <- read.delim('arbol_test.csv', sep=",", head = TRUE)
colnames(data)
pred <- predict(tree, test, type="class")
data <- read.delim('arbol_train.csv', sep=",", head = TRUE)
colnames(data)
tree <- rpart(Confirmed ~ ., data, method="class", minsplit = 2)
rpart.plot(tree)
test <- read.delim('arbol_test.csv', sep=",", head = TRUE)
colnames(data)
pred <- predict(tree, test, type="class")
conf <- table(test$Survived, pred)
test <- read.delim('arbol_test.csv', sep=",", head = TRUE)
colnames(data)
pred <- predict(tree, test, type="class")
conf <- table(test$Confirmed, pred)
acc <- sum(diag(conf)) / sum(conf)
print(acc)
test <- read.delim('arbol_test.csv', sep=",", head = TRUE)
colnames(data)
pred <- predict(tree, test, type="class")
conf <- table(test$Confirmed, pred)
acc <- sum(diag(conf)) / sum(conf)
print(acc)
test <- read.delim('arbol_test.csv', sep=",", head = TRUE)
colnames(data)
pred <- predict(tree, test, type="class")
conf <- table(test$Confirmed, pred)
acc <- sum(diag(conf)) / sum(conf)
print(acc)
pred <- predict(tree, test, type="class")
conf <- table(test$Confirmed, pred)
acc <- sum(diag(conf)) / sum(conf)
print(acc)
pred <- predict(tree, test, type="class")
conf <- table(test$Confirmed, pred)
pred <- predict(tree, test, type="class")
conf <- table(test$Confirmed, pred)
View(conf)
pred <- predict(tree, test, type="class")
conf <- table(test$Confirmed, pred)
View(conf)
acc <- sum(diag(conf)) / sum(conf)
print(acc)
pred <- predict(tree, test, type="class")
conf <- table(test$Confirmed, pred)
View(conf)
acc <- sum(diag(conf)) / sum(conf)
print(acc)
install.packages("rattle")
library(rpart)
library(rpart.plot)
data <- read.delim('datos/arbol_train.csv', sep=",", head = TRUE)
colnames(data)
tree <- rpart(Confirmed ~ ., data, method="class", minsplit = 2)
rpart.plot(tree)
test <- read.delim('datos/arbol_test.csv', sep=",", head = TRUE)
colnames(data)
pred <- predict(tree, test, type="class")
conf <- table(test$Confirmed, pred)
View(conf)
acc <- sum(diag(conf)) / sum(conf)
print(acc)
data <- read.delim('datos/regresion_train.csv', sep=",", head = TRUE)
regresion <- lm(Confirmed~ObservationDate, data = data)
summary(regresion)
plot(data$ObservationDate, data$Confirmed, xlab='ObservationDate', ylab='Confirmed')
abline(regresion)
confirmed <- data.frame(ObservationDate = 09282020)
predict(regresion, confirmed)
tree <- rpart(Confirmed ~ ., data, method="class", minsplit = 2)
pruned <- prune(tree, cp = 0.01)
rpart.plot(pruned)
tree <- rpart(Confirmed ~ ., data, method="class", minsplit = 2)
rpart.plot(tree)
tree <- rpart(Confirmed ~ ., data, method="class", minsplit = 2)
rpart.plot(tree)
data <- read.delim('datos/arbol_train.csv', sep=",", head = TRUE)
colnames(data)
tree <- rpart(Confirmed ~ ., data, method="class", minsplit = 2)
rpart.plot(tree)
pruned <- prune(tree, cp = 0.01)
pruned <- prune(tree, cp = 0.01)
fancyRpartPlot(pruned)
pruned <- prune(tree, cp = 0.01)
rpart.plot(pruned)
pruned <- prune(tree, cp = 0.1)
rpart.plot(pruned)
pruned <- prune(tree, cp = 0.001)
rpart.plot(pruned)
pruned <- prune(tree, cp = 0.0001)
rpart.plot(pruned)
pruned <- prune(tree, cp = 0.1)
rpart.plot(pruned)
pruned <- prune(tree, cp = 0.15)
rpart.plot(pruned)
pruned <- prune(tree, cp = 0.015)
rpart.plot(pruned)
pred <- predict(tree, test, type="class")
conf <- table(test$Confirmed, pred)
View(conf)
acc <- sum(diag(conf)) / sum(conf)
print(acc)
View(data)
data <- read.delim('datos/regresion_train.csv', sep=",", head = TRUE)
View(data)
install.packages("keras")
library(keras)
install_keras()
# Cargar de conjunto de entrenamiento de imágenes numéricas
mnist <- dataset_mnist()
View(test)
View(test)
yes
View(test)
# Cargar de conjunto de entrenamiento de imágenes numéricas
test <- read.delim('datos/arbol_test.csv', sep=",", head = TRUE)
train <- read.delim('datos/regresion_train.csv', sep=",", head = TRUE)
date_train <- train$ObservationDate
confirmed_train <- train$Confirmed
date_test <- test$ObservationDate
confirmed_test <- test$Confirmed
# Definir el modelo
model <- keras_model_sequential()
library(naivebayes)
install.packages("naivebayes")
library(naivebayes)
install.packages("naivebayes")
install.packages("naivebayes")
install.packages("naivebayes")
install.packages("naivebayes")
# creamos el modelo de pronostico
data <- read.delim('datos/regresion_train.csv', sep=",", head = TRUE)
m <- naive_bayes(confirmed ~ ObservationDate, data = data)#, laplace = 1)
# creamos el modelo de pronostico
data <- read.delim('datos/regresion_train.csv', sep=",", head = TRUE)
m <- naive_bayes(confirmed ~ ObservationDate, data = data)#, laplace = 1)
library(naivebayes)
# creamos el modelo de pronostico
data <- read.delim('datos/regresion_train.csv', sep=",", head = TRUE)
m <- naive_bayes(confirmed ~ ObservationDate, data = data)#, laplace = 1)
View(data)
# creamos el modelo de pronostico
data <- read.delim('datos/regresion_train.csv', sep=",", head = TRUE)
m <- naive_bayes(Confirmed ~ ObservationDate, data = data)#, laplace = 1)
# creamos el modelo de pronostico
data <- read.delim('datos/regresion_train.csv', sep=",", head = TRUE)
m <- naive_bayes(Confirmed ~ ObservationDate, data = data)#, laplace = 1)
# creamos el modelo de pronostico
data <- read.delim('datos/regresion_train.csv', sep=",", head = TRUE)
m <- naive_bayes(Confirmed ~ ObservationDate + Country, data = data)#, laplace = 1)
# creamos el modelo de pronostico
data <- read.delim('datos/regresion_train.csv', sep=",", head = TRUE)
m <- naive_bayes(Confirmed ~ ObservationDate + Country, data = data)#, laplace = 1)
# creamos el modelo de pronostico
data <- read.delim('datos/regresion_train.csv', sep=",", head = TRUE)
m <- naive_bayes(Confirmed ~ ObservationDate + Country, data = data)#, laplace = 1)
# creamos el modelo de pronostico
data <- read.delim('datos/regresion_train.csv', sep=",", head = TRUE)
m <- naive_bayes(Confirmed ~ ObservationDate + Country, data = data)#, laplace = 1)
# creamos el modelo de pronostico
data <- read.delim('datos/regresion_train.csv', sep=",", head = TRUE)
m <- naive_bayes(Confirmed ~., data = data)#, laplace = 1)
test <- read.delim('datos/arbol_test.csv', sep=",", head = TRUE)
colnames(data)
pred <- predict(tree, test, type="class")
data <- read.delim('datos/arbol_train.csv', sep=",", head = TRUE)
colnames(data)
tree <- rpart(Confirmed ~ ., data, method="class", minsplit = 2)
install.packages("rattle")
library(rpart)
library(rpart.plot)
data <- read.delim('datos/arbol_train.csv', sep=",", head = TRUE)
colnames(data)
tree <- rpart(Confirmed ~ ., data, method="class", minsplit = 2)
rpart.plot(tree)
test <- read.delim('datos/arbol_test.csv', sep=",", head = TRUE)
colnames(data)
pred <- predict(tree, test, type="class")
conf <- table(test$Confirmed, pred)
View(conf)
acc <- sum(diag(conf)) / sum(conf)
print(acc)
View(data)
# creamos el modelo de pronostico
data <- read.delim('datos/regresion_train.csv', sep=",", head = TRUE)
reg <- glm(Confirmed ~ ObservationDate, data = data, family = binomial)
# creamos el modelo de pronostico
data_sintomas <- read.delim('datos_sintomas/Cleaned_Data.csv', sep=",", head = TRUE)
# creamos el modelo de pronostico
data_sintomas <- read.delim('datos_sintomas/Cleaned-Data.csv', sep=",", head = TRUE)
reg <- glm(Confirmed ~ ObservationDate, data = data, family = binomial)
View(data_sintomas)
# creamos el modelo de pronostico
data_sintomas <- read.delim('datos_sintomas/Cleaned-Data.csv', sep=",", head = TRUE)
reg <- glm(Sevirity_Severe ~ Age_60., data = data_sintomas, family = binomial)
# creamos el modelo de pronostico
data_sintomas <- read.delim('datos_sintomas/Cleaned-Data.csv', sep=",", head = TRUE)
reg <- glm(Severity_Severe ~ Age_60., data = data_sintomas, family = binomial)
summary(reg)
# creamos el modelo de pronostico
reg <- glm(Severity_Severe ~ Age_60., data = data_sintomas, family = binomial)
summary(reg)
# representamos graficamente el modelo
plot(m)
# creamos el modelo de pronostico
m <- naive_bayes(Severity_Severe ~ Age_60., data = data_sintomas)#, laplace = 1)
# creamos el modelo de pronostico
m <- naive_bayes(Severity_Severe ~ Age_60. + Gender_Female, data = data_sintomas)#, laplace = 1)
# creamos el modelo de pronostico
m <- naive_bayes(Severity_Severe ~ Age_60. + Gender_Female, data = data_sintomas)#, laplace = 1)
# creamos el modelo de pronostico
m <- naive_bayes(Severity_Severe ~ Age_60. + Gender_Female, data = data_sintomas)#, laplace = 1)
# creamos el modelo de pronostico
m <- naive_bayes(Severity_Severe ~ Age_60. + Gender_Female, data = data_sintomas)#, laplace = 1)
# creamos el modelo de pronostico
reg <- glm(Severity_Severe ~ Age_60., data = data_sintomas, family = binomial)
datos_probab <- data.frame(temperatura = seq(50, 85, 0.1))
datos.predict <- predict(reg, datos_probab, type = "response")  # por defecto calcularía log p_i/(1-p_i), para calcular p_i usamos el argumento type
# creamos el modelo de pronostico
reg <- glm(Severity_Severe ~ Age_60, data = data_sintomas, family = binomial)
# creamos el modelo de pronostico
reg <- glm(Severity_Severe ~ Age_60., data = data_sintomas, family = binomial)
datos_probab <- data.frame(temperatura = seq(50, 85, 0.1))
datos.predict <- predict(reg, datos_probab, type = "response")  # por defecto calcularía log p_i/(1-p_i), para calcular p_i usamos el argumento type
# creamos el modelo de pronostico
reg <- glm(Severity_Severe ~ Age_60., data = data_sintomas, family = binomial)
datos_probab <- data.frame(Severity_Severe))
# creamos el modelo de pronostico
reg <- glm(Severity_Severe ~ Age_60., data = data_sintomas, family = binomial)
datos_probab <- data.frame(Severity_Severe)
# creamos el modelo de pronostico
reg <- glm(Severity_Severe ~ Age_60., data = data_sintomas, family = binomial)
datos_probab <- data.frame(data_sintomas)
datos.predict <- predict(reg, datos_probab, type = "response")  # por defecto calcularía log p_i/(1-p_i), para calcular p_i usamos el argumento type
plot(data_sintomas$Severity_Severe, data_sintomas$Age_60., pch = 21, bg = colores,  xlab = "Temperatura", ylab = "Prob. defecto")
install.packages("randomForest")
library(randomForest)
# creamos el modelo de pronostico
modelo <- randomForest(Severity_Severe~., data=data_sintomas)
# creamos el modelo de pronostico
nb_laplace1 <- naiveBayes(Severity_Severe~., data=data_sintomas, laplace=1)
library(e1071)
install.packages("e1071")
library(e1071)
data_sintomas <- read.delim('datos_sintomas/Cleaned-Data.csv', sep=",", head = TRUE)
# creamos el modelo de pronostico
nb_laplace1 <- naiveBayes(Severity_Severe~., data=data_sintomas, laplace=1)
laplace1_pred <- predict(nb_laplace1, test, type="class")
# creamos el modelo de pronostico
nb_laplace1 <- naiveBayes(Severity_Severe~., data=data_sintomas, laplace=1)
# creamos el modelo de pronostico
nb_laplace1 <- naiveBayes(Severity_Severe~., data=data_sintomas, laplace=1)
test <- naive_data[(nrow(naive_data)*.7+1):nrow(naive_data),]
# creamos el modelo de pronostico
nb_laplace1 <- naiveBayes(Severity_Severe~., data=data_sintomas, laplace=1)
test <- naive_data[(nrow(data_sintomas)*.7+1):nrow(data_sintomas),]
# creamos el modelo de pronostico
nb_laplace1 <- naiveBayes(Severity_Severe~., data=data_sintomas, laplace=1)
test <- data_sintomas[(nrow(data_sintomas)*.7+1):nrow(data_sintomas),]
View(test)
# creamos el modelo de pronostico
nb_laplace1 <- naiveBayes(Severity_Severe~., data=data_sintomas, laplace=1)
test <- data_sintomas[(nrow(data_sintomas)*.7+1):nrow(data_sintomas),]
default_pred <- predict(nb_default, test, type="class")
# creamos el modelo de pronostico
nb_laplace1 <- naiveBayes(Severity_Severe~., data=data_sintomas, laplace=1)
laplace1_pred <- predict(nb_laplace1, test, type="class")
default_pred <- predict(nb_default, test, type="class")
# creamos el modelo de pronostico
nb_laplace1 <- naiveBayes(Severity_Severe~., data=data_sintomas, laplace=1)
laplace1_pred <- predict(nb_laplace1, test, type="class")
table(laplace1_pred, test$response,dnn=c("Prediction","Actual"))
View(data_sintomas)
data_sintomas <- read.delim('datos_sintomas/Cleaned-Data.csv', sep=",", head = TRUE)
# creamos el modelo de pronostico
locmodel <- naive_bayes(Severerty_Severe ~ Age_60., data = data_sintomas)
library(naivebayes)
# creamos el modelo de pronostico
locmodel <- naive_bayes(Severerty_Severe ~ Age_60., data = data_sintomas)
# creamos el modelo de pronostico
locmodel <- naive_bayes(Severety_Severe ~ Age_60., data = data_sintomas)
# creamos el modelo de pronostico
locmodel <- naive_bayes(Severety_Severe ~ Age_60., data = data_sintomas)
# creamos el modelo de pronostico
locmodel <- naive_bayes(Severety_Severe ~ Age_60., data = data_sintomas)
data_sintomas <- read.delim('datos_sintomas/Cleaned-Data.csv', sep=",", head = TRUE)
# creamos el modelo de pronostico
locmodel <- naive_bayes(Severety-Severe ~ Age_60., data = data_sintomas)
# creamos el modelo de pronostico
locmodel <- naive_bayes(Severity_Severe ~ Age_60., data = data_sintomas)
# creamos el modelo de pronostico
locmodel <- naive_bayes(Severity_Severe ~ as.character(Age_60.), data = data_sintomas)
# creamos el modelo de pronostico
locmodel <- naive_bayes(Severity_Severe ~ as.character(Age_60.), data = data_sintomas)
# creamos el modelo de pronostico
locmodel <- naive_bayes(Severity_Severe ~ Age_60., data = data_sintomas)
# creamos el modelo de pronostico
locmodel <- naive_bayes(Severity_Severe ~ Age_60., data = data_sintomas)
# creamos el modelo de pronostico
locmodel <- naive_bayes(Severity_Severe ~ Age_60., data = data_sintomas)
# creamos el modelo de pronostico
locmodel <- naive_bayes(Severity_Severe ~ Age_60., data = data_sintomas)
# creamos el modelo de pronostico
locmodel <- naive_bayes(Severity_Severe ~ as.binary(Age_60.), data = data_sintomas)
# creamos el modelo de pronostico
locmodel <- naive_bayes(Severity_Severe ~ as.binary(Age_60.), data = data_sintomas)
# creamos el modelo de pronostico
locmodel <- naive_bayes(Severity_Severe ~ as.number(Age_60.), data = data_sintomas)
# creamos el modelo de pronostico
locmodel <- naive_bayes(Severity_Severe ~ as.number(Age_60.), data = data_sintomas)
View(data)
library(keras)
library(keras)
model <- keras_model_sequential()
library(keras)
model <- keras_model_sequential()
library(keras)
model <- keras_model_sequential()
library(keras)
model <- keras_model_sequential()
library(keras)
model <- keras_model_sequential()
library(keras)
model <- keras_model_sequential()
library(keras)
model <- keras_model_sequential()
library(keras)
model <- keras_model_sequential()
library(keras)
model <- keras_model_sequential()
library(keras)
model <- keras_model_sequential()
library(keras)
model <- keras_model_sequential()
library(keras)
model <- keras_model_sequential()
library(keras)
model <- keras_model_sequential()
library(keras)
install_tensorflow()
library(keras)
install_keras()
install_keras()
library(keras)
model <- keras_model_sequential()
library(tensorflow)
library(keras)
library(tensorflow)
install_keras()
library(keras)
library(tensorflow)
model <- keras_model_sequential()
install_keras()
detach("package:tensorflow", unload = TRUE)
detach("package:keras", unload = TRUE)
detach("package:tensorflow", unload = TRUE)
install_keras()
library(keras)
library(keras)
library(tensorflow)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(keras)
library(naivebayes)
# creamos el modelo de pronostico
nb <- naive_bayes(confirmed ~ ., data, usepoisson = TRUE)
# creamos el modelo de pronostico
nb <- naive_bayes(Confirmed ~ ., data, usepoisson = TRUE)
# creamos el modelo de pronostico
nb <- naive_bayes(as.factor(Confirmed) ~ ., data, usepoisson = TRUE)
# creamos el modelo de pronostico
nb <- naive_bayes(as.factor(Confirmed) ~ ObservationDate, data, usepoisson = TRUE)
# creamos el modelo de pronostico
nb <- naive_bayes(as.factor(Confirmed) ~ ObservationDate, data, usepoisson = TRUE)
# creamos el modelo de pronostico
nb <- naive_bayes(as.factor(Confirmed) ~ ObservationDate, data, usepoisson = TRUE)
# creamos el modelo de pronostico
nb <- naive_bayes(as.factor(Confirmed) ~ ObservationDate, data, usepoisson = TRUE)
# creamos el modelo de pronostico
nb <- naive_bayes(as.factor(Confirmed) ~ ObservationDate, data, usepoisson = TRUE)
# creamos el modelo de pronostico
nb <- naive_bayes(as.factor(Confirmed) ~ ObservationDate, data, usepoisson = TRUE)
# creamos el modelo de pronostico
nb <- naive_bayes(as.factor(Confirmed) ~ ObservationDate, data, usepoisson = TRUE)
# creamos el modelo de pronostico
nb <- naive_bayes(as.factor(Confirmed) ~ ObservationDate, data, usepoisson = TRUE)
# creamos el modelo de pronostico
nb <- naive_bayes(as.factor(Confirmed) ~ ObservationDate, data, usepoisson = TRUE)
# creamos el modelo de pronostico
nb <- naive_bayes(as.factor(Confirmed) ~ ObservationDate, data, usepoisson = TRUE)
View(nb)
# creamos el modelo de pronostico
nb <- naive_bayes(as.factor(Confirmed) ~ ObservationDate, data, usepoisson = TRUE)
nb <- naive_bayes(as.factor(Severity_Severe) ~., data_sintomas, usepoisson = TRUE)
# creamos el modelo de pronostico
nb <- naive_bayes(as.factor(Confirmed) ~ ObservationDate, data, usepoisson = TRUE)
nb <- naive_bayes(as.factor(Severity_Severe) ~ Age_60., data_sintomas, usepoisson = TRUE)
predict(nb, 09282020)
predict(nb, test)
# creamos el modelo de pronostico
nb <- naive_bayes(as.factor(Severity_Severe) ~ Age_60., data_sintomas, usepoisson = TRUE)
nb <- naive_bayes(as.factor(Confirmed) ~ ObservationDate, data, usepoisson = TRUE)
predict(nb, test)
View(test)
data <- read.delim('datos/regresion_train.csv', sep=",", head = TRUE)
test <- read.delim('datos/arbol_test.csv', sep=",", head = TRUE)
colnames(data)
predict(nb, test)
# creamos el modelo de pronostico
nb <- naive_bayes(as.factor(Severity_Severe) ~ Age_60., data_sintomas, usepoisson = TRUE)
nb <- naive_bayes(as.factor(Confirmed) ~ ObservationDate + Country, data, usepoisson = TRUE)
# creamos el modelo de pronostico
nb2 <- naive_bayes(as.factor(Severity_Severe) ~ Age_60., data_sintomas, usepoisson = TRUE)
nb1 <- naive_bayes(as.factor(Confirmed) ~ ObservationDate, data, usepoisson = TRUE)
predict(nb, test)
install.packages("naivebayes")
install.packages("naivebayes")
test[0,3]
data <- read.delim('datos/arbol_train.csv', sep=",", head = TRUE)
colnames(data)
test <- read.delim('datos/arbol_test.csv', sep=",", head = TRUE)
colnames(data)
test[0,3]
test[3,]
predict(nb1, test[3,])
# creamos el modelo de pronostico
nb2 <- naive_bayes(as.factor(Severity_Severe) ~ Age_60., data_sintomas, usepoisson = TRUE)
library(naivebayes)
data_sintomas <- read.delim('datos_sintomas/Cleaned-Data.csv', sep=",", head = TRUE)
# creamos el modelo de pronostico
nb2 <- naive_bayes(as.factor(Severity_Severe) ~ Age_60., data_sintomas, usepoisson = TRUE)
nb1 <- naive_bayes(as.factor(Confirmed) ~ ObservationDate, data, usepoisson = TRUE)
predict(nb1, test[3,])
predict(nb1, test[3,])
test[3,]
View(data)
View(test)
View(data)
data <- read.delim('datos/regresion_train.csv', sep=",", head = TRUE)
# creamos el modelo de pronostico
nb2 <- naive_bayes(as.factor(Severity_Severe) ~ Age_60., data_sintomas, usepoisson = TRUE)
nb1 <- naive_bayes(as.factor(Confirmed) ~ ObservationDate, data, usepoisson = TRUE)
predict(nb1, test[3,])
View(data)
# Installing
install.packages("tibble")
# Loading
library("tibble")
nro <- 1:12
jugadores <- tibble(x = c(-1, -2, 8, 7, -12, -15, -13, 15, 21, 12, -25, 26),
y = c(1, -3, 6, -8, 8, 0, -10, 16, 2, -15, 1, 0))
jugadores %>%
ggplot() +
aes(x, y, label = nro) +
geom_point(size = 5) +
geom_text(nudge_x = 1.3, nudge_y = 1.3)
tree <- rpart(Season ~ New.cases + New.deaths + New.recovered, data_arbol, method="class")
=======
install.packages("viridis")
library(viridis)
colores <- magma(256)
Heatmap(matrix = data, name = "mtcars",
col = colores,
row_title = "observaciones",
column_title = "variables",
row_names_gp = gpar(fontsize = 7),
clustering_distance_columns = "euclidean",
clustering_distance_rows = "euclidean",
clustering_method_columns = "average",
clustering_method_rows = "average")
wss <- 0
i <- 1000000
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[i] <- km.out$cluster
i<-i+1
}
install.packages("dbscan")
library("dbscan")
data <- read.delim('datos_nuevos_casos/regresion_train.csv', sep=",", head = TRUE)
data$Seasson <- NULL
head(data)
wss <- 0
i <- 1000000
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[i] <- km.out$cluster
i<-i+1
}
wss <- 0
i <- 1000000
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[i] <- km.out$cluster
i<-i+1000
}
plot(1:15, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[i] <- km.out$cluster
i<-i+1000000
}
plot(1:15, wss, type = "b", xlab = "Number of Clusters")
print(wss.length)
print(length(wss))
wss <- 0
i <- 1000000
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[length(wss)] <- km.out$cluster
i<-i+1000000
}
plot(1:15, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[length(wss)] <- km.out$cluster
i<-i+1000000
}
plot(1:15, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[length(wss)] <- km.out$cluster
i<-i+1000000
}
print(wss)
plot(1:15, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[length(wss)] <- km.out$cluster
i<-i+1000000
print(i)
}
print(wss)
plot(1:15, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
print(length(wss))
wss[length(wss)] <- km.out$cluster
i<-i+1000000
print(i)
}
print(wss)
plot(1:15, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
print(index)
wss[index] <- km.out$cluster
i<-i+1000000
index <- index + 1
print(i)
}
print(wss)
plot(1:15, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
print(index)
wss[index] <- km.out$cluster
i<-i+1000000
index <- index + 1
print(i)
}
print(wss)
plot(1:15, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
i<-i+1000000
index <- index + 1ç
wss <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
i<-i+1000000
index <- index + 1
}
print(wss)
plot(1:15, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
i<-i+1000000
index <- index + 1
}
plot(1:15, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
i<-i+1000000
index <- index + 1
}
plot(1:1, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
i<-i+1000000
index <- index + 1
}
plot(1:1, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
i<-i+1000000
index <- index + 1
}
plot(1:5, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
i<-i+1000000
index <- index + 1
}
plot(1:5, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
i<-i+1000000
index <- index + 1
}
plot(1:6, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
i<-i+1000000
index <- index + 1
}
plot(1:4, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
i<-i+1000000
index <- index + 1
}
print(index)
plot(1:4, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
i<-i+1000000
index <- index + 1
}
print(index)
plot(1:index-1, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
i<-i+1000000
index <- index + 1
}
print(index)
plot(1:(index-1), wss, type = "b", xlab = "Number of Clusters")
wss <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
i<-i+1000000
index <- index + 1
}
plot(1:(index-1), wss, type = "b", xlab = "Number of Clusters")
wss <- 0
value <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
value[index] <- i
i<-i+1000000
index <- index + 1
}
plot(value, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
value <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
value[index] <- i
i<-i+1000000
index <- index + 1
}
plot(value, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
value <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
value[index] <- i
i<-i+100000
index <- index + 1
}
plot(value, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
value <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
value[index] <- i
i<-i+10000
index <- index + 1
}
plot(value, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
value <- 0
i <- 1000000
index <- 0
while(i<=5000000) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
value[index] <- i
i<-i+1000
index <- index + 1
}
plot(value, wss, type = "b", xlab = "Number of Clusters")
wss <- 0
value <- 0
i <- 0
index <- 0
while(i<=4) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
value[index] <- i
i<-i+0.1
index <- index + 1
}
plot(value, wss, type = "b", xlab = "Valor de EPS", ylab="Number of Clusters")
wss <- 0
value <- 0
i <- 0
index <- 0
while(i<=10) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
value[index] <- i
i<-i+0.1
index <- index + 1
}
plot(value, wss, type = "b", xlab = "Valor de EPS", ylab="Number of Clusters")
wss <- 0
value <- 0
i <- 0
index <- 0
while(i<=10) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
value[index] <- i
i<-i+0.1
print(i)
index <- index + 1
}
plot(value, wss, type = "b", xlab = "Valor de EPS", ylab="Number of Clusters")
wss <- 0
value <- 0
i <- 0
index <- 0
while(i<=50) {
km.out <- dbscan(data,eps=i,MinPts = 5)
wss[index] <- km.out$cluster
value[index] <- i
i<-i+0.1
print(i)
index <- index + 1
}
plot(value, wss, type = "b", xlab = "Valor de EPS", ylab="Number of Clusters")
data <- read.delim('datos_nuevos_casos/regresion_train.csv', sep=",", head = TRUE, row.names = 1,
as.is=TRUE)
data$Seasson <- as.numeric(as.factor(data$Seasson))
head(data)
data <- as.matrix(data)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("ComplexHeatmap")
library(ComplexHeatmap)
install.packages("viridis")
library(viridis)
colores <- magma(256)
Heatmap(matrix = data, name = "mtcars",
col = colores,
row_title = "observaciones",
column_title = "variables",
row_names_gp = gpar(fontsize = 7),
clustering_distance_columns = "euclidean",
clustering_distance_rows = "euclidean",
clustering_method_columns = "average",
clustering_method_rows = "average")
data <- read.delim('datos_nuevos_casos/regresion_train.csv', sep=",", head = TRUE, row.names = 1,
as.is=TRUE)
data$Seasson <- as.numeric(as.factor(data$Seasson))
head(data)
data <- as.matrix(data)
data <- scale(data)
Heatmap(matrix = data, name = "mtcars",
col = colores,
row_title = "observaciones",
column_title = "variables",
row_names_gp = gpar(fontsize = 7),
clustering_distance_columns = "euclidean",
clustering_distance_rows = "euclidean",
clustering_method_columns = "average",
clustering_method_rows = "average")
data <- read.delim('datos_nuevos_casos/regresion_train.csv', sep=",", head = TRUE, row.names = 1,
as.is=TRUE)
data$Seasson <- as.numeric(as.factor(data$Seasson))
head(data)
data <- as.matrix(data)
data <- scale(data)
Heatmap(matrix = data, name = "mtcars",
col = colores,
row_title = "observaciones",
column_title = "variables",
row_names_gp = gpar(fontsize = 7),
clustering_distance_columns = "euclidean",
clustering_distance_rows = "euclidean",
clustering_method_columns = "average",
clustering_method_rows = "average")
Heatmap(matrix = data, name = "mtcars",
row_title = "observaciones",
column_title = "variables",
row_names_gp = gpar(fontsize = 7),
clustering_distance_columns = "euclidean",
clustering_distance_rows = "euclidean",
clustering_method_columns = "average",
clustering_method_rows = "average")
data <- read.delim('datos_nuevos_casos/regresion_train.csv', sep=",", head = TRUE, row.names = 1,
as.is=TRUE)
data$Seasson <- as.numeric(as.factor(data$Seasson))
head(data)
data <- as.matrix(data)
Heatmap(matrix = data, name = "mtcars",
row_title = "observaciones",
column_title = "variables",
row_names_gp = gpar(fontsize = 7),
clustering_distance_columns = "euclidean",
clustering_distance_rows = "euclidean",
clustering_method_columns = "average",
clustering_method_rows = "average")
data <- read.delim('datos_nuevos_casos/regresion_train.csv', sep=",", head = TRUE, row.names = 1,
as.is=TRUE)
data$Seasson <- as.numeric(as.factor(data$Seasson))
head(data)
data <- as.matrix(data)
data <- scale(data)
Heatmap(matrix = data, name = "mtcars",
row_title = "observaciones",
column_title = "variables",
row_names_gp = gpar(fontsize = 7),
clustering_distance_columns = "euclidean",
clustering_distance_rows = "euclidean",
clustering_method_columns = "average",
clustering_method_rows = "average")
data <- read.delim('datos_nuevos_casos/regresion_train.csv', sep=",", head = TRUE, row.names = 1,
as.is=TRUE)
data$Seasson <- as.numeric(as.factor(data$Seasson))
head(data)
data <- as.matrix(data)
data <- scale(data)
Heatmap(matrix = data, name = "mtcars",
row_title = "observaciones",
column_title = "variables",
row_names_gp = gpar(fontsize = 7),
clustering_distance_columns = "euclidean",
clustering_distance_rows = "euclidean",
clustering_method_columns = "average",
clustering_method_rows = "average")
data <- read.delim('datos_nuevos_casos/regresion_train.csv', sep=",", head = TRUE, row.names = 1,
as.is=TRUE)
head(data)
data <- as.matrix(data)
data <- scale(data)
data <- read.delim('datos_nuevos_casos/regresion_train.csv', sep=",", head = TRUE, row.names = 1,
as.is=TRUE)
data$Seasson <- NULL
head(data)
data <- as.matrix(data)
data <- scale(data)
Heatmap(matrix = data, name = "mtcars",
row_title = "observaciones",
column_title = "variables",
row_names_gp = gpar(fontsize = 7),
clustering_distance_columns = "euclidean",
clustering_distance_rows = "euclidean",
clustering_method_columns = "average",
clustering_method_rows = "average")
Heatmap(matrix = data, name = "mtcars",
row_title = "observaciones",
column_title = "variables",
row_names_gp = gpar(fontsize = 7),
clustering_distance_columns = "euclidean",
clustering_distance_rows = "euclidean",
clustering_method_columns = "average",
clustering_method_rows = "average")
data <- read.delim('datos_nuevos_casos/regresion_train.csv', sep=",", head = TRUE, row.names = 1,
as.is=TRUE)
data$Seasson <- as.numeric(as.factor(data$Seasson))
head(data)
data <- as.matrix(data)
data <- scale(data)
Heatmap(matrix = data, name = "mtcars",
row_title = "observaciones",
column_title = "variables",
row_names_gp = gpar(fontsize = 7),
clustering_distance_columns = "euclidean",
clustering_distance_rows = "euclidean",
clustering_method_columns = "average",
clustering_method_rows = "average")
Heatmap(matrix = data, name = "Clusters",
row_title = "observaciones",
column_title = "variables",
row_names_gp = gpar(fontsize = 7),
clustering_distance_columns = "euclidean",
clustering_distance_rows = "euclidean",
clustering_method_columns = "average",
clustering_method_rows = "average")
>>>>>>> 8b7f3618fd7a18f57a70913c6649b34d5575fdb7
